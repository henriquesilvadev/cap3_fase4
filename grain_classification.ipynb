{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Grain Classification using CRISP-DM\n",
                "\n",
                "## 1. Analysis and Preprocessing\n",
                "\n",
                "In this section, we will load the dataset, analyze its structure, visualize distributions and relationships, and preprocess the data for modeling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set visualization style\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define column names based on dataset description\n",
                "columns = [\n",
                "    'Area',\n",
                "    'Perimeter',\n",
                "    'Compactness',\n",
                "    'Kernel_Length',\n",
                "    'Kernel_Width',\n",
                "    'Asymmetry_Coeff',\n",
                "    'Kernel_Groove_Length',\n",
                "    'Class'\n",
                "]\n",
                "\n",
                "# Load the dataset\n",
                "df = pd.read_csv('seeds_dataset.txt', sep='\\t+', header=None, names=columns, engine='python')\n",
                "\n",
                "# Display first rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Descriptive Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Data Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Histograms\n",
                "df.hist(figsize=(12, 10), bins=20)\n",
                "plt.suptitle('Feature Distributions', fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Boxplots\n",
                "plt.figure(figsize=(15, 10))\n",
                "for i, col in enumerate(df.columns[:-1]):\n",
                "    plt.subplot(3, 3, i+1)\n",
                "    sns.boxplot(x='Class', y=col, data=df)\n",
                "    plt.title(f'{col} by Class')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pairplot to see relationships\n",
                "sns.pairplot(df, hue='Class', palette='viridis')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.4 Missing Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.5 Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "X = df.drop('Class', axis=1)\n",
                "y = df['Class']\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
                "df_scaled['Class'] = y\n",
                "\n",
                "df_scaled.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Implementation and Comparison\n",
                "\n",
                "We will implement and compare the following algorithms:\n",
                "- K-Nearest Neighbors (KNN)\n",
                "- Support Vector Machine (SVM)\n",
                "- Random Forest\n",
                "- Naive Bayes\n",
                "- Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
                "\n",
                "# Initialize models\n",
                "models = {\n",
                "    'KNN': KNeighborsClassifier(),\n",
                "    'SVM': SVC(),\n",
                "    'Random Forest': RandomForestClassifier(random_state=42),\n",
                "    'Naive Bayes': GaussianNB(),\n",
                "    'Logistic Regression': LogisticRegression(random_state=42)\n",
                "}\n",
                "\n",
                "# Train and evaluate\n",
                "results = {}\n",
                "\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    results[name] = acc\n",
                "    \n",
                "    print(f\"--- {name} ---\")\n",
                "    print(f\"Accuracy: {acc:.4f}\")\n",
                "    print(classification_report(y_test, y_pred))\n",
                "    print(\"Confusion Matrix:\")\n",
                "    print(confusion_matrix(y_test, y_pred))\n",
                "    print(\"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare performance\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x=list(results.keys()), y=list(results.values()))\n",
                "plt.title('Model Accuracy Comparison')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim(0.8, 1.0)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Optimization\n",
                "\n",
                "We will use Grid Search to optimize the hyperparameters of the best performing models (likely SVM and Random Forest)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# SVM Optimization\n",
                "param_grid_svm = {\n",
                "    'C': [0.1, 1, 10, 100],\n",
                "    'gamma': [1, 0.1, 0.01, 0.001],\n",
                "    'kernel': ['rbf', 'linear']\n",
                "}\n",
                "\n",
                "grid_svm = GridSearchCV(SVC(), param_grid_svm, refit=True, verbose=2)\n",
                "grid_svm.fit(X_train, y_train)\n",
                "\n",
                "print(\"Best SVM Parameters:\", grid_svm.best_params_)\n",
                "print(\"Best SVM Score:\", grid_svm.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest Optimization\n",
                "param_grid_rf = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 10, 20, 30],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "\n",
                "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, refit=True, verbose=2)\n",
                "grid_rf.fit(X_train, y_train)\n",
                "\n",
                "print(\"Best Random Forest Parameters:\", grid_rf.best_params_)\n",
                "print(\"Best Random Forest Score:\", grid_rf.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Optimized Models\n",
                "print(\"--- Optimized SVM ---\")\n",
                "y_pred_svm = grid_svm.predict(X_test)\n",
                "print(classification_report(y_test, y_pred_svm))\n",
                "\n",
                "print(\"--- Optimized Random Forest ---\")\n",
                "y_pred_rf = grid_rf.predict(X_test)\n",
                "print(classification_report(y_test, y_pred_rf))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}